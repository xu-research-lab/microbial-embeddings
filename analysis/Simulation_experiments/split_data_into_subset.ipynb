{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table_all = pd.read_csv('Data/original_data_files/final_abundance_table_v46_rarefied.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobalSpecies0001</th>\n",
       "      <th>GlobalSpecies0002</th>\n",
       "      <th>GlobalSpecies0003</th>\n",
       "      <th>GlobalSpecies0004</th>\n",
       "      <th>GlobalSpecies0005</th>\n",
       "      <th>GlobalSpecies0006</th>\n",
       "      <th>GlobalSpecies0007</th>\n",
       "      <th>GlobalSpecies0008</th>\n",
       "      <th>GlobalSpecies0009</th>\n",
       "      <th>GlobalSpecies0010</th>\n",
       "      <th>...</th>\n",
       "      <th>GlobalSpecies0991</th>\n",
       "      <th>GlobalSpecies0992</th>\n",
       "      <th>GlobalSpecies0993</th>\n",
       "      <th>GlobalSpecies0994</th>\n",
       "      <th>GlobalSpecies0995</th>\n",
       "      <th>GlobalSpecies0996</th>\n",
       "      <th>GlobalSpecies0997</th>\n",
       "      <th>GlobalSpecies0998</th>\n",
       "      <th>GlobalSpecies0999</th>\n",
       "      <th>GlobalSpecies1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sample1</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample2</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample999996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample999997</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample999998</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample999999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample1000000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999876 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               GlobalSpecies0001  GlobalSpecies0002  GlobalSpecies0003  \\\n",
       "Sample1                       11                  0                  0   \n",
       "Sample2                       12                  0                  0   \n",
       "Sample3                        0                  0                  0   \n",
       "Sample4                        0                  0                  0   \n",
       "Sample5                        0                  0                  0   \n",
       "...                          ...                ...                ...   \n",
       "Sample999996                   0                  0                  0   \n",
       "Sample999997                   0                  2                  0   \n",
       "Sample999998                   2                  0                  0   \n",
       "Sample999999                   0                  0                  0   \n",
       "Sample1000000                  0                  0                  0   \n",
       "\n",
       "               GlobalSpecies0004  GlobalSpecies0005  GlobalSpecies0006  \\\n",
       "Sample1                        0                  0                  0   \n",
       "Sample2                        0                  0                  0   \n",
       "Sample3                        0                  0                  0   \n",
       "Sample4                        0                  0                  0   \n",
       "Sample5                        0                  0                  0   \n",
       "...                          ...                ...                ...   \n",
       "Sample999996                   0                  0                  0   \n",
       "Sample999997                   0                  0                  0   \n",
       "Sample999998                   0                  0                  0   \n",
       "Sample999999                   0                  0                  0   \n",
       "Sample1000000                  0                  0                  0   \n",
       "\n",
       "               GlobalSpecies0007  GlobalSpecies0008  GlobalSpecies0009  \\\n",
       "Sample1                        0                  0                  0   \n",
       "Sample2                        0                 11                  0   \n",
       "Sample3                        0                  0                  0   \n",
       "Sample4                        0                  0                  0   \n",
       "Sample5                        0                  2                  0   \n",
       "...                          ...                ...                ...   \n",
       "Sample999996                   0                 11                  0   \n",
       "Sample999997                   0                 26                  0   \n",
       "Sample999998                   0                  0                  0   \n",
       "Sample999999                   0                  3                  0   \n",
       "Sample1000000                  0                 18                  0   \n",
       "\n",
       "               GlobalSpecies0010  ...  GlobalSpecies0991  GlobalSpecies0992  \\\n",
       "Sample1                        0  ...                 31                  0   \n",
       "Sample2                        0  ...                  0                  0   \n",
       "Sample3                        0  ...                  0                 14   \n",
       "Sample4                        0  ...                 34                  0   \n",
       "Sample5                        0  ...                  0                  0   \n",
       "...                          ...  ...                ...                ...   \n",
       "Sample999996                   0  ...                  0                  0   \n",
       "Sample999997                   0  ...                  0                  0   \n",
       "Sample999998                   0  ...                  0                  0   \n",
       "Sample999999                  12  ...                 17                  0   \n",
       "Sample1000000                  0  ...                  1                  0   \n",
       "\n",
       "               GlobalSpecies0993  GlobalSpecies0994  GlobalSpecies0995  \\\n",
       "Sample1                        0                  0                  0   \n",
       "Sample2                        0                  0                  0   \n",
       "Sample3                        0                  0                  0   \n",
       "Sample4                        0                  0                  5   \n",
       "Sample5                       22                  0                  1   \n",
       "...                          ...                ...                ...   \n",
       "Sample999996                   0                  0                  0   \n",
       "Sample999997                   0                  0                  0   \n",
       "Sample999998                   0                  0                  0   \n",
       "Sample999999                   0                  0                  0   \n",
       "Sample1000000                  4                  0                  0   \n",
       "\n",
       "               GlobalSpecies0996  GlobalSpecies0997  GlobalSpecies0998  \\\n",
       "Sample1                        0                  0                  0   \n",
       "Sample2                        2                  2                  0   \n",
       "Sample3                       29                  0                  0   \n",
       "Sample4                        0                  0                  0   \n",
       "Sample5                        5                  0                  5   \n",
       "...                          ...                ...                ...   \n",
       "Sample999996                   0                  0                  0   \n",
       "Sample999997                   4                  0                  0   \n",
       "Sample999998                   0                  0                  0   \n",
       "Sample999999                   0                  0                  7   \n",
       "Sample1000000                  0                  0                  0   \n",
       "\n",
       "               GlobalSpecies0999  GlobalSpecies1000  \n",
       "Sample1                        9                  0  \n",
       "Sample2                        0                  0  \n",
       "Sample3                        0                  0  \n",
       "Sample4                        0                  0  \n",
       "Sample5                        2                  0  \n",
       "...                          ...                ...  \n",
       "Sample999996                   0                  0  \n",
       "Sample999997                   0                  0  \n",
       "Sample999998                   0                  0  \n",
       "Sample999999                   1                  0  \n",
       "Sample1000000                  0                  0  \n",
       "\n",
       "[999876 rows x 1000 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_table_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import biom\n",
    "import os\n",
    "import h5py # BIOM HDF5 格式通常需要这个\n",
    "from sklearn.utils import shuffle as sk_shuffle # 用于打乱索引\n",
    "\n",
    "def create_and_save_biom_subsets(\n",
    "    df_abundance: pd.DataFrame,\n",
    "    subset_size: int,\n",
    "    num_subsets: int = 5,\n",
    "    output_folder: str = \"biom_subsets\",\n",
    "    random_seed: int = 42\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    对输入的丰度表DataFrame进行预处理，随机抽取指定数量和大小的子集，\n",
    "    并将每个子集以BIOM格式保存到指定文件夹。\n",
    "\n",
    "    参数:\n",
    "    df_abundance (pd.DataFrame): 输入的丰度表，行为样本，列为OTU。\n",
    "    subset_size (int): 每个抽取的子集应包含的样本数量。\n",
    "    num_subsets (int, optional): 要抽取的子集数量。默认为5。\n",
    "    output_folder (str, optional): 用于存储生成的BIOM文件的文件夹名称。默认为 \"biom_subsets\"。\n",
    "    random_seed (int, optional): 用于随机数生成的种子，以保证结果可复现。默认为42。\n",
    "\n",
    "    返回:\n",
    "    list: 一个包含所有成功生成的BIOM文件路径的列表。\n",
    "    \"\"\"\n",
    "\n",
    "    # 0. 输入验证\n",
    "    if not isinstance(df_abundance, pd.DataFrame):\n",
    "        raise ValueError(\"输入 'df_abundance' 必须是一个 Pandas DataFrame。\")\n",
    "    if df_abundance.empty:\n",
    "        raise ValueError(\"输入的DataFrame为空。\")\n",
    "    if not isinstance(subset_size, int) or subset_size <= 0:\n",
    "        raise ValueError(\"'subset_size' 必须是一个正整数。\")\n",
    "    if not isinstance(num_subsets, int) or num_subsets <= 0:\n",
    "        raise ValueError(\"'num_subsets' 必须是一个正整数。\")\n",
    "    # if df_abundance.shape[0] < subset_size * num_subsets:\n",
    "    #     raise ValueError(\n",
    "    #         f\"DataFrame中的总样本数 ({df_abundance.shape[0]}) \"\n",
    "    #         f\"不足以创建 {num_subsets} 个大小为 {subset_size} 的无重叠子集。\"\n",
    "    #         f\"至少需要 {subset_size * num_subsets} 个样本。\"\n",
    "    #     )\n",
    "\n",
    "    # 1. 预处理：填充NaN并设定随机种子\n",
    "    print(\"步骤1: 预处理DataFrame...\")\n",
    "    df_filled = df_abundance.fillna(0)\n",
    "    print(f\" - NaN值已用0填充。\")\n",
    "\n",
    "    # 使用NumPy的随机状态以更好地控制种子，或者直接用np.random.seed()\n",
    "    # np.random.seed(random_seed) # 全局设定\n",
    "    # 或者创建一个RandomState实例\n",
    "    rng = np.random.RandomState(random_seed)\n",
    "    print(f\" - 随机种子已设置为: {random_seed}\")\n",
    "\n",
    "    # 2. 获取并打乱样本ID（行索引）\n",
    "    all_sample_ids = df_filled.index.tolist()\n",
    "    # shuffled_sample_ids = np.random.permutation(all_sample_ids) # 如果使用全局np.random.seed\n",
    "    shuffled_sample_ids = rng.permutation(all_sample_ids) # 使用rng实例的permutation\n",
    "\n",
    "    # 3. 创建输出文件夹\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    print(f\"\\n步骤2: BIOM文件将保存到文件夹: '{output_folder}'\")\n",
    "\n",
    "    generated_files = []\n",
    "\n",
    "    # 4. 抽取子集并保存为BIOM文件\n",
    "    print(f\"\\n步骤3: 开始抽取 {num_subsets} 个子集，每个子集包含 {subset_size} 个样本...\")\n",
    "    for i in range(num_subsets):\n",
    "        start_index = i * subset_size\n",
    "        end_index = (i + 1) * subset_size\n",
    "        \n",
    "        current_subset_sample_ids = shuffled_sample_ids[start_index:end_index]\n",
    "        df_subset = df_filled.loc[current_subset_sample_ids]\n",
    "        \n",
    "        print(f\"\\n  正在处理子集 {i+1}/{num_subsets} (样本数: {len(df_subset)})...\")\n",
    "\n",
    "        # 将DataFrame转换为BIOM格式所需的输入\n",
    "        # BIOM Table构造函数期望数据是 (observations x samples)\n",
    "        # 我们的df_subset是 (samples x observations/OTUs)\n",
    "        data_matrix = df_subset.values.T  # 转置\n",
    "        observation_ids = df_subset.columns.tolist() # OTU IDs\n",
    "        sample_ids_for_biom = df_subset.index.tolist() # 当前子集的Sample IDs\n",
    "\n",
    "        # 创建BIOM Table对象\n",
    "        try:\n",
    "            table = biom.Table(\n",
    "                data=data_matrix,\n",
    "                observation_ids=observation_ids,\n",
    "                sample_ids=sample_ids_for_biom\n",
    "            )\n",
    "            \n",
    "            # 定义输出文件名\n",
    "            biom_filename = os.path.join(output_folder, f\"subset_{i+1}.biom\")\n",
    "            \n",
    "            # 将BIOM Table对象写入HDF5文件\n",
    "            # 'w'模式会覆盖已存在的文件\n",
    "            with h5py.File(biom_filename, 'w') as hf:\n",
    "                table.to_hdf5(hf, generated_by=f\"create_biom_subsets_function_subset_{i+1}\")\n",
    "            \n",
    "            print(f\"    子集 {i+1} 已成功保存为BIOM文件: {biom_filename}\")\n",
    "            generated_files.append(biom_filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"    错误：创建或保存子集 {i+1} 的BIOM文件时失败: {e}\")\n",
    "            print(f\"      数据矩阵维度: {data_matrix.shape}\")\n",
    "            print(f\"      观察ID数量: {len(observation_ids)}\")\n",
    "            print(f\"      样本ID数量: {len(sample_ids_for_biom)}\")\n",
    "\n",
    "\n",
    "    print(f\"\\n处理完毕。总共生成了 {len(generated_files)} 个BIOM文件。\")\n",
    "    return generated_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n",
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_1000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 1000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 1000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_1000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 1000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_1000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 1000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_1000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 1000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_1000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 1000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_1000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=1000,num_subsets=5,output_folder='Data/data_subset/size_1000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_2000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 2000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 2000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_2000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 2000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_2000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 2000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_2000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 2000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_2000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 2000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_2000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=2000,num_subsets=5,output_folder='Data/data_subset/size_2000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_5000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 5000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 5000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_5000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 5000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_5000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 5000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_5000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 5000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_5000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 5000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_5000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=5000,num_subsets=5,output_folder='Data/data_subset/size_5000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n",
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_10000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 10000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 10000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_10000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 10000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_10000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 10000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_10000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 10000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_10000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 10000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_10000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=10000,num_subsets=5,output_folder='Data/data_subset/size_10000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n",
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_20000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 20000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 20000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_20000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 20000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_20000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 20000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_20000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 20000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_20000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 20000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_20000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=20000,num_subsets=5,output_folder='Data/data_subset/size_20000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n",
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_40000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 40000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 40000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_40000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 40000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_40000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 40000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_40000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 40000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_40000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 40000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_40000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=40000,num_subsets=5,output_folder='Data/data_subset/size_40000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n",
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_80000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 80000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 80000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_80000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 80000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_80000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 80000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_80000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 80000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_80000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 80000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_80000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=80000,num_subsets=5,output_folder='Data/data_subset/size_80000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n",
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_160000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 160000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 160000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_160000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 160000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_160000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 160000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_160000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 160000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_160000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 160000)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_160000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=160000,num_subsets=5,output_folder='Data/data_subset/size_160000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "步骤1: 预处理DataFrame...\n",
      " - NaN值已用0填充。\n",
      " - 随机种子已设置为: 42\n",
      "\n",
      "步骤2: BIOM文件将保存到文件夹: 'data_subset/size_200000'\n",
      "\n",
      "步骤3: 开始抽取 5 个子集，每个子集包含 200000 个样本...\n",
      "\n",
      "  正在处理子集 1/5 (样本数: 200000)...\n",
      "    子集 1 已成功保存为BIOM文件: data_subset/size_200000/subset_1.biom\n",
      "\n",
      "  正在处理子集 2/5 (样本数: 200000)...\n",
      "    子集 2 已成功保存为BIOM文件: data_subset/size_200000/subset_2.biom\n",
      "\n",
      "  正在处理子集 3/5 (样本数: 200000)...\n",
      "    子集 3 已成功保存为BIOM文件: data_subset/size_200000/subset_3.biom\n",
      "\n",
      "  正在处理子集 4/5 (样本数: 200000)...\n",
      "    子集 4 已成功保存为BIOM文件: data_subset/size_200000/subset_4.biom\n",
      "\n",
      "  正在处理子集 5/5 (样本数: 199876)...\n",
      "    子集 5 已成功保存为BIOM文件: data_subset/size_200000/subset_5.biom\n",
      "\n",
      "处理完毕。总共生成了 5 个BIOM文件。\n"
     ]
    }
   ],
   "source": [
    "created_files = create_and_save_biom_subsets(df_abundance=df_table_all,subset_size=200000,num_subsets=5,output_folder='Data/data_subset/size_200000',random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
