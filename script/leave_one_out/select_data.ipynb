{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Constructed from biom file\n",
      "#OTU ID\tS1\tS2\tS4\tS7\n",
      "O1\t2.0\t4.0\t0.0\t5.0\n",
      "O2\t6.0\t0.0\t1.0\t3.0\n",
      "O3\t0.0\t10.0\t0.0\t10.0\n",
      "O4\t1.0\t0.0\t5.0\t0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from biom.table import Table\n",
    "\n",
    "d_a = np.asarray([[2, 0], [6, 1], [1, 5]])\n",
    "t_a = Table(d_a, ['O1', 'O2', 'O4'], ['S1', 'S4'])\n",
    "d_b = np.asarray([[4, 5], [0, 3], [10, 10]])\n",
    "t_b = Table(d_b, ['O1', 'O2', 'O3'], ['S2', 'S7'])\n",
    "merged_table = t_a.merge(t_b)\n",
    "print(merged_table)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB30615.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA742875.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA510730.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB27564.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA594156.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB14674.biom:\n",
      "过滤低频样本和特征，当前维度: (2056, 256)\n",
      "过滤低频样本和特征，处理后的维度: (1393, 255)\n",
      "过滤低频样本和特征，当前维度: (3344, 171)\n",
      "过滤低频样本和特征，处理后的维度: (1437, 171)\n",
      "过滤低频样本和特征，当前维度: (14116, 201)\n",
      "过滤低频样本和特征，处理后的维度: (1624, 201)\n",
      "过滤低频样本和特征，当前维度: (9728, 265)\n",
      "过滤低频样本和特征，处理后的维度: (5514, 253)\n",
      "过滤低频样本和特征，当前维度: (2338, 299)\n",
      "过滤低频样本和特征，处理后的维度: (1167, 288)\n",
      "过滤低频样本和特征，当前维度: (14116, 327)\n",
      "过滤低频样本和特征，处理后的维度: (1442, 327)\n",
      "过滤低频样本和特征，当前维度: (14116, 825)\n",
      "过滤低频样本和特征，处理后的维度: (3283, 825)\n",
      "测试集样本数: 825, 特征数: 7908,训练集样本数: 1495, 特征数: 7908\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA601994.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA742875.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA510730.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB27564.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA594156.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB14674.biom:\n",
      "过滤低频样本和特征，当前维度: (14116, 825)\n",
      "过滤低频样本和特征，处理后的维度: (3283, 825)\n",
      "过滤低频样本和特征，当前维度: (3344, 171)\n",
      "过滤低频样本和特征，处理后的维度: (1437, 171)\n",
      "过滤低频样本和特征，当前维度: (14116, 201)\n",
      "过滤低频样本和特征，处理后的维度: (1624, 201)\n",
      "过滤低频样本和特征，当前维度: (9728, 265)\n",
      "过滤低频样本和特征，处理后的维度: (5514, 253)\n",
      "过滤低频样本和特征，当前维度: (2338, 299)\n",
      "过滤低频样本和特征，处理后的维度: (1167, 288)\n",
      "过滤低频样本和特征，当前维度: (14116, 327)\n",
      "过滤低频样本和特征，处理后的维度: (1442, 327)\n",
      "过滤低频样本和特征，当前维度: (2056, 256)\n",
      "过滤低频样本和特征，处理后的维度: (1393, 255)\n",
      "测试集样本数: 255, 特征数: 8547,训练集样本数: 2065, 特征数: 8547\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA601994.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB30615.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA510730.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB27564.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA594156.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB14674.biom:\n",
      "过滤低频样本和特征，当前维度: (14116, 825)\n",
      "过滤低频样本和特征，处理后的维度: (3283, 825)\n",
      "过滤低频样本和特征，当前维度: (2056, 256)\n",
      "过滤低频样本和特征，处理后的维度: (1393, 255)\n",
      "过滤低频样本和特征，当前维度: (14116, 201)\n",
      "过滤低频样本和特征，处理后的维度: (1624, 201)\n",
      "过滤低频样本和特征，当前维度: (9728, 265)\n",
      "过滤低频样本和特征，处理后的维度: (5514, 253)\n",
      "过滤低频样本和特征，当前维度: (2338, 299)\n",
      "过滤低频样本和特征，处理后的维度: (1167, 288)\n",
      "过滤低频样本和特征，当前维度: (14116, 327)\n",
      "过滤低频样本和特征，处理后的维度: (1442, 327)\n",
      "过滤低频样本和特征，当前维度: (3344, 171)\n",
      "过滤低频样本和特征，处理后的维度: (1437, 171)\n",
      "测试集样本数: 171, 特征数: 8836,训练集样本数: 2149, 特征数: 8836\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA601994.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB30615.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA742875.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB27564.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA594156.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB14674.biom:\n",
      "过滤低频样本和特征，当前维度: (14116, 825)\n",
      "过滤低频样本和特征，处理后的维度: (3283, 825)\n",
      "过滤低频样本和特征，当前维度: (2056, 256)\n",
      "过滤低频样本和特征，处理后的维度: (1393, 255)\n",
      "过滤低频样本和特征，当前维度: (3344, 171)\n",
      "过滤低频样本和特征，处理后的维度: (1437, 171)\n",
      "过滤低频样本和特征，当前维度: (9728, 265)\n",
      "过滤低频样本和特征，处理后的维度: (5514, 253)\n",
      "过滤低频样本和特征，当前维度: (2338, 299)\n",
      "过滤低频样本和特征，处理后的维度: (1167, 288)\n",
      "过滤低频样本和特征，当前维度: (14116, 327)\n",
      "过滤低频样本和特征，处理后的维度: (1442, 327)\n",
      "过滤低频样本和特征，当前维度: (14116, 201)\n",
      "过滤低频样本和特征，处理后的维度: (1624, 201)\n",
      "测试集样本数: 201, 特征数: 8672,训练集样本数: 2119, 特征数: 8672\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA601994.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB30615.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA742875.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA510730.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA594156.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB14674.biom:\n",
      "过滤低频样本和特征，当前维度: (14116, 825)\n",
      "过滤低频样本和特征，处理后的维度: (3283, 825)\n",
      "过滤低频样本和特征，当前维度: (2056, 256)\n",
      "过滤低频样本和特征，处理后的维度: (1393, 255)\n",
      "过滤低频样本和特征，当前维度: (3344, 171)\n",
      "过滤低频样本和特征，处理后的维度: (1437, 171)\n",
      "过滤低频样本和特征，当前维度: (14116, 201)\n",
      "过滤低频样本和特征，处理后的维度: (1624, 201)\n",
      "过滤低频样本和特征，当前维度: (2338, 299)\n",
      "过滤低频样本和特征，处理后的维度: (1167, 288)\n",
      "过滤低频样本和特征，当前维度: (14116, 327)\n",
      "过滤低频样本和特征，处理后的维度: (1442, 327)\n",
      "过滤低频样本和特征，当前维度: (9728, 265)\n",
      "过滤低频样本和特征，处理后的维度: (5514, 253)\n",
      "测试集样本数: 253, 特征数: 5652,训练集样本数: 2067, 特征数: 5652\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA601994.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB30615.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA742875.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA510730.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB27564.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB14674.biom:\n",
      "过滤低频样本和特征，当前维度: (14116, 825)\n",
      "过滤低频样本和特征，处理后的维度: (3283, 825)\n",
      "过滤低频样本和特征，当前维度: (2056, 256)\n",
      "过滤低频样本和特征，处理后的维度: (1393, 255)\n",
      "过滤低频样本和特征，当前维度: (3344, 171)\n",
      "过滤低频样本和特征，处理后的维度: (1437, 171)\n",
      "过滤低频样本和特征，当前维度: (14116, 201)\n",
      "过滤低频样本和特征，处理后的维度: (1624, 201)\n",
      "过滤低频样本和特征，当前维度: (9728, 265)\n",
      "过滤低频样本和特征，处理后的维度: (5514, 253)\n",
      "过滤低频样本和特征，当前维度: (14116, 327)\n",
      "过滤低频样本和特征，处理后的维度: (1442, 327)\n",
      "过滤低频样本和特征，当前维度: (2338, 299)\n",
      "过滤低频样本和特征，处理后的维度: (1167, 288)\n",
      "测试集样本数: 288, 特征数: 8998,训练集样本数: 2032, 特征数: 8998\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA601994.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB30615.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA742875.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA510730.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJEB27564.biom:\n",
      "加载数据集 /home/dongbiao/all_study/data_new/PD/PRJNA594156.biom:\n",
      "过滤低频样本和特征，当前维度: (14116, 825)\n",
      "过滤低频样本和特征，处理后的维度: (3283, 825)\n",
      "过滤低频样本和特征，当前维度: (2056, 256)\n",
      "过滤低频样本和特征，处理后的维度: (1393, 255)\n",
      "过滤低频样本和特征，当前维度: (3344, 171)\n",
      "过滤低频样本和特征，处理后的维度: (1437, 171)\n",
      "过滤低频样本和特征，当前维度: (14116, 201)\n",
      "过滤低频样本和特征，处理后的维度: (1624, 201)\n",
      "过滤低频样本和特征，当前维度: (9728, 265)\n",
      "过滤低频样本和特征，处理后的维度: (5514, 253)\n",
      "过滤低频样本和特征，当前维度: (2338, 299)\n",
      "过滤低频样本和特征，处理后的维度: (1167, 288)\n",
      "过滤低频样本和特征，当前维度: (14116, 327)\n",
      "过滤低频样本和特征，处理后的维度: (1442, 327)\n",
      "测试集样本数: 327, 特征数: 8920,训练集样本数: 1993, 特征数: 8920\n",
      "Processing completed with biom library integration.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import biom\n",
    "import shutil\n",
    "from biom import load_table, Table\n",
    "\n",
    "# 配置路径\n",
    "data_root = \"/home/dongbiao/all_study/data_new\"\n",
    "output_root = \"/home/dongbiao/all_study/result_new\"\n",
    "\n",
    "def filter_low_freq_feature(current_table):\n",
    "  print(f\"过滤低频样本和特征，当前维度: {current_table.shape}\")\n",
    "  sid = current_table.ids(axis=\"sample\")\n",
    "  reads_depth = current_table.sum(axis=\"sample\")\n",
    "  current_table = current_table.filter(\n",
    "      sid[reads_depth > 5000], axis='sample', inplace=False).remove_empty()\n",
    "\n",
    "  fid = current_table.ids(axis=\"observation\")\n",
    "  prevalence = current_table.nonzero_counts(axis=\"observation\")\n",
    "  current_table = current_table.filter(\n",
    "      fid[prevalence > 2], axis='observation', inplace=False).remove_empty()\n",
    "  print(f\"过滤低频样本和特征，处理后的维度: {current_table.shape}\")\n",
    "  return current_table\n",
    "\n",
    "def test_to_aligment_train(test_table, train_tables):\n",
    "  # print(test_table.shape)\n",
    "  # print(train_tables.shape)\n",
    "  # 训练集去空处理，测试集跟训练集进行维度对齐\n",
    "\n",
    "  # 获取训练集的所有特征ID，重新索引测试表的行（特征）以匹配训练集，缺失的特征填充0\n",
    "  train_features = train_tables.ids(axis='observation')\n",
    "  test_df = test_table.to_dataframe()\n",
    "  test_df = test_df.reindex(index=train_features, fill_value=0)\n",
    "\n",
    "  # 创建新的BIOM表，确保特征顺序与训练集一致，过滤掉测试集中不在训练集中的 feature\n",
    "  test_table = Table(\n",
    "      data=test_df.values,\n",
    "      observation_ids=test_df.index.tolist(),\n",
    "      sample_ids=test_df.columns.tolist(),\n",
    "      # observation_metadata=None,  # 可根据需要添加metadata处理\n",
    "      # sample_metadata=test_table.metadata(axis='sample')\n",
    "  )\n",
    "\n",
    "  print(f\"测试集样本数: {test_table.shape[1]}, 特征数: {test_table.shape[0]},训练集样本数: {train_tables.shape[1]}, 特征数: {train_tables.shape[0]}\")\n",
    "\n",
    "  return test_table,train_tables\n",
    "\n",
    "\n",
    "for disease_id in os.listdir(data_root):\n",
    "  disease_dir = os.path.join(data_root, disease_id)\n",
    "  output_disease_dir = os.path.join(output_root, disease_id)\n",
    "\n",
    "  # 跳过非目录和隐藏目录\n",
    "  if not os.path.isdir(disease_dir) or disease_id.startswith('.'):\n",
    "      continue\n",
    "\n",
    " # 只处理PD和SZ\n",
    "  if disease_id not in [ \"PD\"]:\n",
    "    continue\n",
    "\n",
    "  # 获取所有研究数据文件\n",
    "  all_bioms = glob.glob(os.path.join(disease_dir, \"*.biom\"))\n",
    "  \n",
    "  # 执行留一法拆分\n",
    "  for leave_path in all_bioms:\n",
    "    study_code = os.path.splitext(os.path.basename(leave_path))[0]\n",
    "    output_study_dir = os.path.join(output_disease_dir, study_code)\n",
    "\n",
    "    os.makedirs(output_study_dir, exist_ok=True)\n",
    "\n",
    "    # 拷贝元数据文件（新增部分）\n",
    "    src_metadata = os.path.join(disease_dir, \"metadata.tsv\")\n",
    "    dst_metadata = os.path.join(output_disease_dir, \"metadata.tsv\")\n",
    "    if os.path.exists(src_metadata):\n",
    "        os.makedirs(output_disease_dir, exist_ok=True)\n",
    "        shutil.copy2(src_metadata, dst_metadata)\n",
    "    else:\n",
    "        print(f\"警告：{disease_id} 缺失元数据文件\")\n",
    "    \n",
    "    # 构建训练集\n",
    "    train_tables = []\n",
    "    for train_path in all_bioms:\n",
    "        if train_path == leave_path:\n",
    "            continue\n",
    "        try:\n",
    "          train_study_code = os.path.splitext(os.path.basename(train_path))[0]\n",
    "          if disease_id == \"ASD\" and train_study_code == \"PRJEB11419\":\n",
    "            print(f\"{study_code}研究中去除了{disease_id} {train_study_code}\")\n",
    "            continue\n",
    "          # if disease_id == \"PD\" and train_study_code == \"PRJNA601994\":\n",
    "          #   print(f\"{study_code}研究中去除了{disease_id} {train_study_code}\")\n",
    "          #   continue\n",
    "          print(f\"加载数据集 {train_path}:\")\n",
    "          current_table = load_table(train_path)\n",
    "          train_tables.append(current_table)\n",
    "        except Exception as e:\n",
    "            print(f\"加载失败 {train_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 合并训练数据\n",
    "    if not train_tables:\n",
    "        print(f\"警告：{disease_id} 只有一个样本，无法进行留一法拆分\")\n",
    "        continue\n",
    "\n",
    "    merged_train = filter_low_freq_feature(train_tables[0]) \n",
    "    for tbl in train_tables[1:]:\n",
    "        tbl = filter_low_freq_feature(tbl)\n",
    "        merged_train = merged_train.merge(tbl)\n",
    "    merged_train = merged_train.remove_empty()\n",
    "    # 保存测试集副本\n",
    "    test_table = load_table(leave_path)\n",
    "    test_table = filter_low_freq_feature(test_table)\n",
    "\n",
    "    test_table, merged_train = test_to_aligment_train(test_table, merged_train)\n",
    "\n",
    "    # if os.path.exists(output_study_dir):\n",
    "    #   shutil.rmtree(output_study_dir)\n",
    "    #   print(f\"已删除旧目录: {output_study_dir}\")\n",
    "\n",
    "    with biom.util.biom_open(f'{output_study_dir}/train_loo.biom', 'w') as f:\n",
    "      merged_train.to_hdf5(f, \"train\")\n",
    "    with biom.util.biom_open(f'{output_study_dir}/test_loo.biom', 'w') as f:\n",
    "      test_table.to_hdf5(f, \"test\")\n",
    "\n",
    "print(\"Processing completed with biom library integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import biom\n",
    "import shutil\n",
    "from biom import load_table, Table\n",
    "\n",
    "# 配置路径\n",
    "data_root = \"/home/dongbiao/all_study/data_new\"\n",
    "output_root = \"/home/dongbiao/all_study/result_new\"\n",
    "\n",
    "def filter_low_freq_feature(current_table):\n",
    "  print(f\"过滤低频样本和特征，当前维度: {current_table.shape}\")\n",
    "  sid = current_table.ids(axis=\"sample\")\n",
    "  reads_depth = current_table.sum(axis=\"sample\")\n",
    "  current_table = current_table.filter(\n",
    "      sid[reads_depth > 5000], axis='sample', inplace=False).remove_empty()\n",
    "\n",
    "  fid = current_table.ids(axis=\"observation\")\n",
    "  prevalence = current_table.nonzero_counts(axis=\"observation\")\n",
    "  current_table = current_table.filter(\n",
    "      fid[prevalence > 2], axis='observation', inplace=False).remove_empty()\n",
    "  print(f\"过滤低频样本和特征，处理后的维度: {current_table.shape}\")\n",
    "  return current_table\n",
    "\n",
    "def test_to_aligment_train(test_table, train_tables):\n",
    "  # print(test_table.shape)\n",
    "  # print(train_tables.shape)\n",
    "  # 训练集去空处理，测试集跟训练集进行维度对齐\n",
    "\n",
    "  # 获取训练集的所有特征ID，重新索引测试表的行（特征）以匹配训练集，缺失的特征填充0\n",
    "  train_features = train_tables.ids(axis='observation')\n",
    "  test_df = test_table.to_dataframe()\n",
    "  test_df = test_df.reindex(index=train_features, fill_value=0)\n",
    "\n",
    "  # 创建新的BIOM表，确保特征顺序与训练集一致，过滤掉测试集中不在训练集中的 feature\n",
    "  test_table = Table(\n",
    "      data=test_df.values,\n",
    "      observation_ids=test_df.index.tolist(),\n",
    "      sample_ids=test_df.columns.tolist(),\n",
    "      # observation_metadata=None,  # 可根据需要添加metadata处理\n",
    "      # sample_metadata=test_table.metadata(axis='sample')\n",
    "  )\n",
    "\n",
    "  print(f\"测试集样本数: {test_table.shape[1]}, 特征数: {test_table.shape[0]},训练集样本数: {train_tables.shape[1]}, 特征数: {train_tables.shape[0]}\")\n",
    "\n",
    "  return test_table,train_tables\n",
    "\n",
    "\n",
    "for disease_id in os.listdir(data_root):\n",
    "  disease_dir = os.path.join(data_root, disease_id)\n",
    "  output_disease_dir = os.path.join(output_root, disease_id)\n",
    "\n",
    "  # 跳过非目录和隐藏目录\n",
    "  if not os.path.isdir(disease_dir) or disease_id.startswith('.'):\n",
    "      continue\n",
    "\n",
    " # 只处理PD和SZ\n",
    "  if disease_id not in [ \"PD\"]:\n",
    "    continue\n",
    "\n",
    "  # 获取所有研究数据文件\n",
    "  all_bioms = glob.glob(os.path.join(disease_dir, \"*.biom\"))\n",
    "  \n",
    "  # 执行留一法拆分\n",
    "  for leave_path in all_bioms:\n",
    "    study_code = os.path.splitext(os.path.basename(leave_path))[0]\n",
    "    output_study_dir = os.path.join(output_disease_dir, study_code)\n",
    "\n",
    "    os.makedirs(output_study_dir, exist_ok=True)\n",
    "\n",
    "    # 拷贝元数据文件（新增部分）\n",
    "    src_metadata = os.path.join(disease_dir, \"metadata.tsv\")\n",
    "    dst_metadata = os.path.join(output_disease_dir, \"metadata.tsv\")\n",
    "    if os.path.exists(src_metadata):\n",
    "        os.makedirs(output_disease_dir, exist_ok=True)\n",
    "        shutil.copy2(src_metadata, dst_metadata)\n",
    "    else:\n",
    "        print(f\"警告：{disease_id} 缺失元数据文件\")\n",
    "    \n",
    "    # 构建训练集\n",
    "    train_tables = []\n",
    "    for train_path in all_bioms:\n",
    "        if train_path == leave_path:\n",
    "            continue\n",
    "        try:\n",
    "          train_study_code = os.path.splitext(os.path.basename(train_path))[0]\n",
    "          if disease_id == \"ASD\" and train_study_code == \"PRJEB11419\":\n",
    "            print(f\"{study_code}研究中去除了{disease_id} {train_study_code}\")\n",
    "            continue\n",
    "          # if disease_id == \"PD\" and train_study_code == \"PRJNA601994\":\n",
    "          #   print(f\"{study_code}研究中去除了{disease_id} {train_study_code}\")\n",
    "          #   continue\n",
    "          print(f\"加载数据集 {train_path}:\")\n",
    "          current_table = load_table(train_path)\n",
    "          train_tables.append(current_table)\n",
    "        except Exception as e:\n",
    "            print(f\"加载失败 {train_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # 合并训练数据\n",
    "    if not train_tables:\n",
    "        print(f\"警告：{disease_id} 只有一个样本，无法进行留一法拆分\")\n",
    "        continue\n",
    "\n",
    "    merged_train = filter_low_freq_feature(train_tables[0]) \n",
    "    for tbl in train_tables[1:]:\n",
    "        tbl = filter_low_freq_feature(tbl)\n",
    "        merged_train = merged_train.merge(tbl)\n",
    "    merged_train = merged_train.remove_empty()\n",
    "    # 保存测试集副本\n",
    "    test_table = load_table(leave_path)\n",
    "    test_table = filter_low_freq_feature(test_table)\n",
    "\n",
    "    test_table, merged_train = test_to_aligment_train(test_table, merged_train)\n",
    "\n",
    "    # if os.path.exists(output_study_dir):\n",
    "    #   shutil.rmtree(output_study_dir)\n",
    "    #   print(f\"已删除旧目录: {output_study_dir}\")\n",
    "\n",
    "    with biom.util.biom_open(f'{output_study_dir}/train_loo.biom', 'w') as f:\n",
    "      merged_train.to_hdf5(f, \"train\")\n",
    "    with biom.util.biom_open(f'{output_study_dir}/test_loo.biom', 'w') as f:\n",
    "      test_table.to_hdf5(f, \"test\")\n",
    "\n",
    "print(\"Processing completed with biom library integration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总丰度序列：27764.012269938652\n",
      "总丰度序列：7316.02027027027\n",
      "\n",
      "最终结果前5行：\n",
      "             method1  method2\n",
      "SRR10305328  39769.0  40968.0\n",
      "SRR10305329  43962.0  13535.0\n",
      "SRR10305330  46034.0      NaN\n",
      "SRR10305331  37479.0    476.0\n",
      "SRR10305332  34912.0  11942.0\n",
      "...              ...      ...\n",
      "SRR10305419  48980.0  10025.0\n",
      "SRR10305420  48069.0  20487.0\n",
      "SRR10305421  65539.0   5870.0\n",
      "SRR10305422  88127.0  35072.0\n",
      "SRR10305423  56769.0  39751.0\n",
      "\n",
      "[96 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import biom\n",
    "import pandas as pd\n",
    "\n",
    "def load_aligned_sums(biom_path, metadata_path, fill_missing=0):\n",
    "    \"\"\"\n",
    "    对齐BIOM和metadata的样本，处理缺失样本\n",
    "    :param fill_missing: 缺失样本填充值（建议0或np.nan）\n",
    "    :return: 对齐后的总丰度序列\n",
    "    \"\"\"\n",
    "    # 加载元数据\n",
    "    metadata = pd.read_csv(metadata_path, sep='\\t')\n",
    "    metadata_samples = set(metadata['sample'])\n",
    "    \n",
    "    # 加载BIOM数据\n",
    "    table = biom.load_table(biom_path)\n",
    "    biom_df = table.to_dataframe()\n",
    "    biom_samples = set(biom_df.index)\n",
    "    \n",
    "    # 找出不匹配的样本\n",
    "    feature_sum = biom_df.T.sum(axis=1) \n",
    "\n",
    "\n",
    "    feature_sum = feature_sum.mean()\n",
    "    print(f\"总丰度序列：{feature_sum}\")\n",
    "    return feature_sum\n",
    "\n",
    "# 示例用法\n",
    "metadata_path = '/home/dongbiao/all_study/result_new/ASD/metadata.tsv'\n",
    "method1_sums = load_aligned_sums('/home/dongbiao/all_study/result_new/ASD/PRJEB11419/test_loo.biom', metadata_path, fill_missing=0)\n",
    "method2_sums = load_aligned_sums('/home/dongbiao/all_study/data/Agp_Austim/test_loo.biom', metadata_path, fill_missing=0)\n",
    "\n",
    "# 合并结果\n",
    "\n",
    "# 添加元数据信息（可选）\n",
    "# metadata = pd.read_csv(metadata_path,sep='\\t').set_index('sample')\n",
    "# result_df = result_df.join(metadata, how='left')\n",
    "\n",
    "print(\"\\n最终结果前5行：\")\n",
    "print(result_df)\n",
    "\n",
    "# # 加载两个数据集\n",
    "# df1, metadata = load_biom_data('/home/dongbiao/all_study/result_new/ASD/PRJNA578223/test_loo.biom', '/home/dongbiao/all_study/result_new/ASD/metadata.tsv')\n",
    "# df2, _ = load_biom_data('/home/dongbiao/all_study/result/PRJNA578223/test_loo.biom', '/home/dongbiao/all_study/result_new/ASD/metadata.tsv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "102628eab260ad4ed5a43928781c1ea7c3212cf04414eb73b92140452745d199"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
